---
title: 'Models'
description: 'One of our core-values is to build a tool which is model-agnostic. That means, that we do not want to trap the user in one model, but give the choice which model to use. Each model has different strengths and we encourage you to test the different models to find the best models for your specific need.'
---

# Selecting a model
- Whenever you start a new chat, you can use the model you want to work with at the top left.
- You can still change the model at the top left if you have already started a chat. For example, you can start with GPT-4o and, after three messages, switch to Claude 3 Sonnnet.
- When you switch models in an ongoing chat, the entire context of the previous chat history and your data (documents, texts, websites) is always passed to the selected model. So, you don’t need to worry about keeping the context when switching models.
- As no data is ever stored in the models, the system provides all context to the model with every request you make.
- You can also set your personal default model in the account settings [here](https://app.langdock.com/settings/account/preferences). The default for new users is GPT-4o.


# Model overview
Here is a description of the most-used models:

## OpenAI
OpenAI is the most famous AI company and known for its advanced language models, the GPT series. OpenAI also emphasizes ethical AI development, ensuring that their technologies are used responsibly and align with human values.

### GPT-4o
GPT-4o is the latest and best model from OpenAI. It has a similar quality as the previous version of GPT-4 (in rare cases a slightly worse quality was observed), but operates at a higher speed - similar to GPT-3.5. It is the most used model on Langdock and a good allrounder with satisfactory performance in most situations.

GPT-4o is capable of analyzing, describing or comparing images. Simply press the upload button in the chat input field or drag and drop an image into the field to upload it.

You can also set the model as your personal default model in your [preferences](https://app.langdock.com/settings/account/preferences). This will automatically pre-select the model in any new conversation.

### GPT-4
The older version of GPT-4 was released in early 2024. It still provides qualitative outputs but at a slower speed than GPT-4o. There are exceptions, where GPT-4 provides more suitable results than the newer version, but for most users we recommend switching to GPT-4o.

GPT-4 is not able to analyze images. Please switch to GPT-4o or the Claude models for that.

### GPT-3.5
The older model from OpenAI is GPT-3.5. When it came out, it was the best model and fascinated users with its intelligence and capabilities. By now, the newer models from OpenAI, Anthropic, and Mistral have a higher quality, with sometimes an equal or even better speed. GPT-3.5 will be deprecated eventually.

### DALL-E 3
For generating images, we use the latest image generation model from OpenAI. All models (including the ones not from OpenAI) are able to call the model and have an image generated. Each individual model writes a prompt based on your that is sent to the image model. As these prompts might differ from model to model, it makes sense to try different models. The response also includes a description of the image, which is not generated by DALL-E, but the other models.

We recommend GPT-4o or Claude Sonnet for the best results based on our experience and feedback from users.

## Anthropic
Anthropic is an AI research company focused on creating AI systems that are interpretable, reliable, and aligned with human intentions. Their models are designed with a strong emphasis on safety and robustness, aiming to address risks associated with AI technologies.

### Claude 3
The Claude 3 family is built by Anthropic and according to some sources more trustworthy and reliable than other models. It hallucinates less and is better at some reasoning tasks. The family consists of three different models, each with their performance levels (speed, quality and costs), which allows users to choose the right model for their specific need.

Generally, the models are good in these areas and, in some areas, even better than GPT-4:
- Text creation: The tone and style are more natural and human than texts from GPT-4.
- Refusing to answer: GPT-4 sometimes refuses to answer and says it could not access the web / the attached document / analyze the provided image. We have not observed this with Claude.
- Image analysis/vision: The Claude models can also analyze uploaded images.
- Coding: Claude 3 seems to be better in some reasoning and coding tasks.

### Haiku
The smallest model of the family is comparable to GPT-3.5 in its quality. It might reach its limits with reasoning or more nuanced tasks, but is good for translations, instant answers and extraction of knowledge from data.

### Sonnet
The second model, Sonnet, balances intelligence and speed which makes it the go-to model for most cases. We recommend it especially for text creation and every use case where you need some written output as the answers sound more human than from other AI models.

### Opus
The larger Opus model is good at performing complex reasoning tasks, like research, drug discovery or coding. It also performs well in strategic analyses and analysing graphs and trends.

### Claude 3.5 Sonnet (coming soon)
The latest update from Anthropic brought Claude 3.5 Sonnet. It is the most intelligent model with a higher speed and more qualitative answers. It is recommended for complex tasks like coding, strategy, reasoning, and text generation.

It is also considered to be the first equally good model to the OpenAI models.

## Mistral
Mistral is a French AI company focused on developing language models that excel in both performance and efficiency. The company was praised for its open-source approach with many models, increasing transparency for users and researchers.

### Mistral Large
Mistral’s flagship model, Mistral Large, has good reasoning capabilities and is good at coding, maths and follows instructions precisely. It has native mult-lingual capabilities, especially in French, German, Spanish and Italian.

### Mistral Small
Mistral Small is the smaller version of Mistral Large. Similarly to Anthropic’s Claude 3 Haiku model, it has a lower quality than Mistral Large, but is faster, making it more suitable for less complex but faster tasks.

# Context Window Sizes

| Model                 | Context Window Size                    |
| ----------------------| ------------------------------------- |
| GPT-4o                | 128k tokens                     |
| GPT-4 Turbo           | 128k tokens                          |
| GPT-3.5               | 16k tokens |
| Claude 3 Haiku        | 200k tokens |
| Claude 3 Sonnet       | 200k tokens |
| Claude 3 Opus         | 200k tokens |
| Mistral Large         | 16k tokens |