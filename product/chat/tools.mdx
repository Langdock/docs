---
title: 'Chat Tools'
description: 'The chat allows you to send prompts to different AI models and receive a response based on your question. You can use various tools to work with documents, search the web, or perform other operations in the chat. These tools are different capabilities the models have. Describe what you want to do, and the model will choose the right tool automatically based on your request.'
---

<Tip>The **more context and details** you add, the better your response because the model understands precisely what you expect. Do not miss our [Prompt Engineering Guide](https://docs.langdock.com/ressources/prompt-elements) to learn how to write great prompts.</Tip>

## Writing text
The basic functionality in the chat is to use the model without any external sources. The models have been trained on large amounts of data, making them knowledgeable of many topics. You can ask for specific definitions, ask to explain a topic for exactly your use case, or generate texts.
The typical use cases of using the plain model are:
Creating texts, like marketing copy, emails, speeches
Using the model knowledge to learn about a topic, receive definitions or explanations
Use the model’s creativity for brainstorming or receiving feedback
Writing and debugging code

## Document search
Document search is one tool the AI models have. You can add documents by either uploading them, through drag and drop or by selecting a file from an integration (how to set up integrations can be read **here**).

If you attach a document to a chat, the document search tool will automatically be used. Document search extracts text from files, such as PDFs, Word documents, or PowerPoint presentations. You will find a list of all supported file types **here**.

The document's text is sent to the model in the context window, together with the prompt. The document text is then used to answer the question asked by the user.

Use cases for working with documents are:
- Summarizing texts
- Asking questions about a document
- Analyzing the files

**Limitations:**
Models are not good at retrieving data in tables from documents. Instead, we advise using the data analyst with a CSV, Excel, or Google Sheets or screenshotting the table and working with the screenshot instead. Also, it is not possible to extract images, graphs, or symbols which are not characters.

## Web search
Web search is a way to access the web and to deal with one technical limitation of AI models. Large language models go through two phases: The model training, when it is “built,” and the phase when training is completed and the model can be used. Once the model training is completed, the model can not learn anything anymore and will not know about events or data that are past that time (“model cutoff date” - read our [guide about how AI works](https://docs.langdock.com/ressources/basics) for more details). Therefore, the models are immediately outdated after they have been finished.

To still access relevant information past the knowledge cutoff date, the model can use the web search tool. The web search consists of two steps:

1. First, a search query is defined and the internet is searched for relevant results.
2. Afterward, the results are sent to the model together with the prompt, and with this information, an answer is generated.

The Web search can be used to:
- Gather information on a specific topic
- Use up-to-date information
- Put a URL in the prompt and search that specific site
 
## Image analysis (Vision)
Apart from uploading text files, you can also upload images (JPG, PNG) to the chat and let the model analyze them. This capability is called “vision”. The following models support it:
- GPT-4o
- GPT-4o mini
- Claude 3.5 Sonnet
- Claude 3 Haiku
- Claude 3 Sonnet
- Claude 3 Opus
- Gemini 1.5 Pro
- Gemini 1.5 Flash

Image analysis is limited to images uploaded in the chat and not available in uploaded PDFs or presentations yet.

## Image Generation
The models can call another model in the background to generate images. The current image model in Langdock is Dall-E3 by OpenAI.
Image generation uses the following steps:

1. The model you selected chooses the image generation tool and writes a prompt to the image model in the background.
2. The image model generates the image based on the prompt and returns it to the main model and you as the user.

You can select any language model for image generation. Each model can send prompts to the image model, but the language models prompt the image model differently. Feel free to try different models and see how the generated images differ.

Our resource section contains a short guide about **prompt engineering for image generation**.

## Data Analysis
The data analysis tool in Langdock enables users to (among other things) read and process CSV files, Excel or Google Sheets.

This capability can be used to:
- Read tabular data (CSVs, Excel sheets, and Google Sheets)
- Perform mathematical operations, e.g., finding correlations, defining distributions or deviations, etc.
- Create graphs and charts depicting data
- Generating new files (Excel, CSV, PowerPoint, Word, etc.)

Ask what you are trying to accomplish in the chat. Try to be as specific as possible.

**How the data analyst works:**
The model chooses to use the data analyst tool and generates Python code. Python is a programming language that can be used to analyze datasets and extract information.
A separate instance runs the Python code and returns the result. The model uses the prompt and the result to answer the user's question.

**Limitations:**
The normal document search and the data analyst are different functionalities for different tasks with advantages and disadvantages. The document search is good at understanding a whole document's content. 
The data analyst can not understand the entire file, but only the part that is extracted with Python. Everything else in the file has not been considered for the response. But this makes it powerful in working with large data sets and tabular data, as well as performing mathematical operations.

We have written a guide on **best practices for our data analyst** in our resource section.

## General Chat Limitations
We are constantly working on improving the platform. If you have feedback or suggestions, please let us know at support@langdock.com. 

Here are some known limitations we are working on:
- **Text in images has mistakes / is written in non-existing letters:** <br />
Image models were trained on real images, which included text. Based on the training data, the model generates objects that look similar. The image model can not (yet) write full, correct sentences but tries to mimic letters from the alphabet. This leads to incorrect spelling or non-existing letters. This is a current limitation of image models and will be improved by the model providers in upcoming model versions.

- **I can not paste links to files behind a login (e.g., Google Documents):** <br />
The model accesses the web like you would for the first time when you were not logged in anywhere. Due to this, the model can not read documents behind a login. You can use the integrations to attach documents, search for files, and attach them to the chat.

- **The data analysis does not return anything / returns the wrong value:**
Ensure that your file, especially the header row, is well-structured and has no empty cells. We have included some tricks in our data **analyst guide here** for more items to check.
