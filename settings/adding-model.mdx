---
title: 'Adding your own models'
description: 'In the model settings, admins can add their own AI models.'
---

To add your own models, we have prepared the following guides for you. If you have any questions, do not hesitate to contact the Langdock team.

1. Click on Add Model to add a new model to the platform
2. A modal where you can add models opens. Here, you find two sections. The Display Settings at the top allows you to customize what the user sees in the model selector. The Model Configuration lets you connect your Langdock workspace to your model API.
3. To configure the Display settings, you can follow the following steps. This information is also available by the company hosting the model.
    - The provider is the organization that built and trained the model. This does not necessarily align with the company from which you consume the model. For example, you can use Microsoft Azure to use OpenAI models in the EU. But the provider will still be OpenAI.
    - The model name is the name of the model.
    - The hosting provider is the actual place where you consume the model. For example, GPT-4o can be hosted by Microsoft Azure.
    - The region shows the user where the model is hosted. This can be set to the US or the EU.
    - To give users an indication of how the model performs speed- and quality-wise, you can add a ranking from 1 to 5. Smaller models, like Claude 3 Haiku, GPT-4o mini or Llama 3.1 8B, are faster but do not have the highest quality. The top models, GPT-4o or Claude 3.5, have high output quality.
    - The knowledge cutoff is the date when the model training data ended. Most models have a knowledge cutoff at the end of 2023.
    - The last option allows you to indicate whether the model can analyze images. This information is available from the model provider and the model hoster. Models that allow image analysis are GPT-4o, GPT-4o mini, and the Claude models.
4. To set up the Model Configuration, select the SDK you are using. Below are guides to set up the model correctly sorted by the SDK you are using.

Mistral from Azure:
Make sure to select “Mistral” as the SDK. 


BYOK Models
Mistral - Azure: SDK needs to be set to “Mistral”
Claude - AWS Bedrock: Base URL muss “Zugriffsschlüssel” enthalten.